> _**Due to the COVID-19 pandemic, the HPDC 2020 conference leadership 
> has decided to cancel the physical meeting this year. As a 
> consequence, the P-RECS'20 workshop will take place as a virtual 
> event, with recorded presentations uploaded to YouTube and 
> discussions on the [P-RECS Slack  workspace][joinslack].
> Proceedings will be peer-reviewed and published as originally 
> planned. The deadline has been extended to 04/20/2020 (AOE).
>
> As part of the activities associated to the workshop, we plan to 
> organize a panel/discussion on the [ACM Reproducibility EIG][eig] 
> effort lead by Victoria Stodden and Philippe Bonnet. We would like 
> to find a time during the week of June 22-26 that works for 
> everybody. We will reach out via the EIG mailing list and P-RECS 
> slack workspace to share logistics about this meeting, and request 
> your time preference.**_

[joinslack]: https://join.slack.com/t/p-recs/shared_invite/zt-dlwmr45g-flUnLfAJUbjiwks05Lc6AQ
[eig]: https://www.acm.org/special-interest-groups/eigs

The P-RECS workshop focuses heavily on practical, actionable aspects 
of reproducibility in broad areas of computational science and data 
exploration, with special emphasis on issues in which community 
collaboration can be essential for adopting novel methodologies, 
techniques and frameworks aimed at addressing some of the challenges 
we face today. The workshop brings together researchers and experts to 
share experiences and advance the state of the art in the reproducible 
evaluation of computer systems, featuring contributed papers and 
invited talks.

## Topics

We expect submissions from topics such as, but not limited to:

  * Experiment dependency management.
  * Software citation and persistence.
  * Data versioning and preservation.
  * Provenance of data-intensive experiments.
  * Tools and techniques for incorporating provenance into publications.
  * Automated experiment execution and validation.
  * Experiment portability for code, performance, and related metrics.
  * Experiment discoverability for re-use.
  * Cost-benefit analysis frameworks for reproducibility.
  * Usability and adaptability of reproducibility frameworks into already-established domain-specific tools.
  * Long-term artifact archiving for future reproducibility.
  * Frameworks for sociological constructs to incentivize paradigm shifts.
  * Policies around publication of articles/software.
  * Blinding and selecting artifacts for review while maintaining history.
  * Reproducibility-aware computational infrastructure.
